{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract\n",
    "\n",
    "import requests\n",
    "from psycopg2 import connect, sql\n",
    "\n",
    "# Configure your PostgreSQL connection string\n",
    "conn_string = \"dbname='etl_bites' user='ilhaam.ahmed' password='etl_proj' host='localhost' port='5432'\"\n",
    "\n",
    "def get_data_from_api(url):\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "posts_url = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "users_url = \"https://jsonplaceholder.typicode.com/users\"\n",
    "\n",
    "posts_data = get_data_from_api(posts_url)\n",
    "users_data = get_data_from_api(users_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is fetching data from two different API endpoints (posts and users) using the 'requests' library which I am lready familiar with. It is then storing the retrieved JSON data in the 'posts_data' and 'users_data' variables.\n",
    "\n",
    "Reminder:\n",
    "- 'requests' - sends HTTP requests to web servers and receives responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "\n",
    "def join_posts_and_users(posts, users):\n",
    "    for post in posts:\n",
    "        for user in users:\n",
    "            if post['userId'] == user['id']:\n",
    "                post['author'] = user['name']\n",
    "    return posts\n",
    "\n",
    "combined_data = join_posts_and_users(posts_data, users_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, a join_posts_and_users() function is defined which takes 'posts' and 'users' as parameters. Within the function, a simple join operation is made: so for each post, the function iterates over each element in the users list and checks for matching user and post IDs.\n",
    "\n",
    "Then the data is combined and stored in the 'combine_data' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "# Create tables in analytical DB\n",
    "# This could also be done manually via a GUI (e.g. TablePlus) or with a SQL script\n",
    "def execute_query_postgresql(conn_string, query):\n",
    "    with connect(conn_string) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "\n",
    "create_api_data_table = '''\n",
    "CREATE TABLE api_data (\n",
    "    post_id INTEGER NOT NULL,\n",
    "    title TEXT NOT NULL,\n",
    "    body TEXT NOT NULL,\n",
    "    user_id INTEGER NOT NULL,\n",
    "    author TEXT NOT NULL\n",
    ");\n",
    "'''\n",
    "\n",
    "execute_query_postgresql(conn_string, create_api_data_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next part above, defined the execute_query_postgresql() function to connect to the postgres database and uses cursors to execute the sql queries as well as commit them to the database.\n",
    "\n",
    "Then an 'api_data' table is created with the specific columns.\n",
    "\n",
    "Finally the table created query is executed using the execute_query_postgresql() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the data - Load\n",
    "\n",
    "def insert_data_to_postgresql(conn_string, table_name, data):\n",
    "    with connect(conn_string) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for item in data:\n",
    "                query = sql.SQL(\"INSERT INTO {} (post_id, title, body, user_id, author) VALUES (%s, %s, %s, %s, %s)\").format(sql.Identifier(table_name))\n",
    "                cur.execute(query, (item['id'], item['title'], item['body'], item['userId'], item['author']))\n",
    "        conn.commit()\n",
    "\n",
    "table_name = \"api_data\"\n",
    "insert_data_to_postgresql(conn_string, table_name, combined_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last part defines the insert_data_to_postgresql() function, which is used to insert the fetched API data into a postgres database table called 'api_data'.\n",
    "\n",
    "'connect' is used to establish a connection, then a cursor is used to execute the sql queries.\n",
    "\n",
    "A breakdown of the 'query' variable:\n",
    "- The 'sql.SQL' function is used to format the query and prevent issues (malicious SQL statements being inserted).\n",
    "- The 'sql.Identifier(table_name)' part safely formats the table name as an identifier, which helps prevent SQL injection attacks on the table name.\n",
    "- The 'cur.execute' method executes the query and inserts the data into the table.\n",
    "- The changes are then commited."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytical_databases_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
