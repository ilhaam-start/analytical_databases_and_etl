{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mariadb\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "financial_conn_string = {\n",
    "    'host': 'relational.fit.cvut.cz',\n",
    "    'port': '3306',\n",
    "    'user': 'guest',\n",
    "    'password': 'relational',\n",
    "    'database': 'financial'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I import the necessary library to connect with the MariaDB Database. I then set up the database connection parameters and store this in the 'financial_conn_string' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_from_mariadb(conn_params, query):\n",
    "    with mariadb.connect(**conn_params) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            data = cur.fetchall()\n",
    "            colnames = [desc[0] for desc in cur.description]\n",
    "    return data, colnames\n",
    "\n",
    "financial_query_transactions = \"SELECT * FROM trans;\"\n",
    "financial_data_transactions, transactions_colnames = fetch_data_from_mariadb(financial_conn_string, financial_query_transactions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I define a function to fetch the data from MariaDB. This function takes two arguments:\n",
    "- conn_params = the database connection\n",
    "- query = the sql query to execute.\n",
    "    \n",
    "I used a 'with' statement to create a connection to the MariaDB database using the 'mariadb.connect()' method. \n",
    "I then create a cursor using 'with conn.cursor() as cur' to interact with the database and execute queries.\n",
    "The query is executed using 'cur.execute(query)' and the result is fetched using 'data = cur.fetchall()' and stored in 'data'. The column names are retrieved from the cursors description using a list comprehension 'colnames = [desc[0] for desc in cur.description]' and stored in 'colnames'. I then return the data and colnames.\n",
    "\n",
    "I define a variable called 'financial_query_transactions' and put a SQL SELECT query to fetch all records from the 'trans' table. Finally I use the 'fetch_data_from_mariadb()' function to fetch data from the 'trans' table and store this data in the columns 'financial_data_transactions, transactions_colnames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.DataFrame(financial_data_transactions, columns=transactions_colnames)\n",
    "avg_transaction_amount = transactions_df.groupby('account_id')['amount'].mean().reset_index()\n",
    "avg_transaction_amount.columns = ['AccountID', 'AverageTransactionAmount']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next part of the code, I use the pandas library to manipulate some of the data I fetched.\n",
    "\n",
    "First I load the fetched data into the dataframe and store this in a variable called 'transactions_df'. The columns parameter is set to 'transactions_colnames', which contained the column names fetched earlier.\n",
    "\n",
    "To calculate the average transaction amount I group the data in the dataframe based on the 'account_id' column and then calculates the average(mean) of the 'amount' column within each group. This will give the average transaction amount for each unique account ID.\n",
    "\n",
    "I reset the index of this grouped Dataframe. This converts the group labels (account IDs) back into regular columns.\n",
    "\n",
    "Lastly I rename the columns to 'AccountID', 'AverageTransactionAmount' for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_bites_conn_string = \"\"\"\n",
    "                host='localhost' \n",
    "                port='5432' \n",
    "                dbname='etl_bites' \n",
    "                user='ilhaam.ahmed' \n",
    "                password='dataproj'\n",
    "                \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use psycopg2 to insert the transformed data in bulk into the local PostgreSQL database (etl_bites).\n",
    "We will need a connection string as well for the destination database (our local PostgreSQL one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables in analytical DB\n",
    "# This could also be done manually via a GUI (e.g. TablePlus) or with a SQL script\n",
    "def execute_query_postgresql(conn_string, query):\n",
    "    with psycopg2.connect(conn_string) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "\n",
    "create_average_transaction_amount_table = '''\n",
    "CREATE TABLE average_transaction_amount (\n",
    "    AccountID INTEGER NOT NULL,\n",
    "    AverageTransactionAmount NUMERIC(15, 2) NOT NULL\n",
    ");\n",
    "'''\n",
    "\n",
    "execute_query_postgresql(etl_bites_conn_string, create_average_transaction_amount_table)\n",
    "\n",
    "def insert_data_to_postgresql(conn_string, table_name, data, columns):\n",
    "    with psycopg2.connect(conn_string) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for row in data.itertuples(index=False):\n",
    "                insert_query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))});\"\n",
    "                cur.execute(insert_query, row)\n",
    "            conn.commit()\n",
    "\n",
    "table_name = \"average_transaction_amount\"\n",
    "columns = ['AccountID', 'AverageTransactionAmount']\n",
    "insert_data_to_postgresql(etl_bites_conn_string, table_name, avg_transaction_amount, columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I define a function that is used to execute a SQL query on a postgres database. A cursor is created to execute the query and once the query is executed it is commited to the database.\n",
    "\n",
    "Then I create a variable that stores the SQL query to create a table named 'average_transaction_amount' in the database.\n",
    "\n",
    "This function execute_query_postgresql() is used to execute the query in the database.\n",
    "\n",
    "I then create another function to insert the data into a specified table in the postgres database, it takes four parameters. Inside the function a connection is established with the postgres database. Then a cursor is created to execute the insert queries. For each row in the dataframe, an insert query is constructed using the table_name and columns, The changes are commited to the database.\n",
    "\n",
    "I define the table_name and the list of column names to be used when inserting the data into the average transaction amount table.\n",
    "\n",
    "Finally, I use the insert_data_to_postgresql() function to insert data from the dataframe into the table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytical_databases_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
